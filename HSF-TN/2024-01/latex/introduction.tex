\section{Introduction}\label{introduction}


In the HL-LHC era (to begin in 2029) LHC analysts, depending on the type of analysis they do, may have to process up to an order of magnitude more data than currently. At the same time, there are significant changes to analysis techniques such as the introduction of columnar analysis, parallelised data access and the organization of multi-step workflows into pipelines, some of which may be better suited to run using cloud technologies and heterogeneous resources. Consequently, the analysis infrastructure must evolve. This is an active area of R\&D collectively referred to as “Analysis Facilities”. 

An Analysis Facility (from here on abbreviated to AF) can be defined as infrastructure and services that provide integrated data, software and computational resources to execute one or more elements of an analysis workflow. These resources are shared among members of a Virtual Organization (VO) and supported by the organization. This R\&D is expected to be integrated with the existing infrastructure and guide any future development.   


Since discussions on the evolution of analysis for the HL-LHC started, the analysis infrastructure has often been considered as something separate from the current grid infrastructure, mainly due to two aspects: large scale interactivity for fast analysis cycles and integration of cloud native technologies. The possible additional requirement to support whole VOs also sets it apart from the local Tier 3 sites currently giving access only to local users and occasionally to external collaborators. The nature of AFs has provoked long debates. CERN satisfies the requirements described above but it is the only site supporting all users and the competition for resources there is already quite intense. The question is how to define an AF that offers similar functionalities as those at CERN without hindering participation from other sites. Can they support a subset of functionalities or be open to groups of users and still be considered an AF?

We can start by stating that the most common setup for analysis (small interactive machines, a batch system and a shared file system between the two) will not be replaced and we should focus on a technology refresh. The effort is to complement and add new tools to what already exists.  A second observation is that the distinction between AFs and the Worldwide LHC Computing Grid (WLCG)~\cite{wlcg} is more blurred than currently appreciated and the integration of AFs within existing WLCG infrastructure is important for broad accessibility and a standardized user experience with smooth data access, dynamic allocation of WLCG computing as part of the AF resources and easier support from the sites. A third observation is that several analysis facility sites support multiple experiments, for instance CERN, FNAL and DESY, and the aim is to provide the same infrastructure for most if not all experiments which will not necessarily be only WLCG or even HEP. Interdisciplinarity will have to be taken in consideration when planning the AFs. In other words AFs do not exist in a vacuum and should not be considered isolated and one should not assume the resources are dedicated. The way forward is not to focus on a specific architecture, but on the building blocks that can be deployed whatever shape an AF takes. For these reasons we should talk about “analysis infrastructure” more than “analysis facilities”.

In this spirit, following the Analysis Ecosystem II workshop and the Analysis Facilities Forum presentations, a number of key areas were identified which this white paper addresses:

\begin{itemize}
    \item \textbf{Users' perspective and their use cases} (Section~\ref{userperspective}): this should drive the R\&D and naturally will be discussed first.
    \item \textbf{Compute resources access and provisioning} (Section~\ref{computeresources}): considers the evolution of computing requirements, in particular the concept of scale out resources and integration on existing infrastructures.
    \item \textbf{Data Organisation, Management, Access (DOMA)} (Section~\ref{doma}): concerns the input/output data for analysis workflows. In particular the need to integrate AFs with grid storage and methods to solve the data locality problem. 
    \item \textbf{Federated Identity Management and and Authentication, Authorization Infrastructure (AAI)} (Section~\ref{aai}): a consistent AAI across analysis infrastructure is at the core of a smooth integration particularly for data access; federated identity can also allow access to multiple facilities. 
    \item \textbf{Accelerator resources} (Section~\ref{accelerators}): considers the increased use of accelerators in analysis and the resulting need to add accelerators to AF resources.
    \item \textbf{Analysis portability and preservation}(Section~\ref{preservation}): handles the requirements on the packaging of software to enable collaborative analysis across facilities with the ability to rerun or recast analyses in the future. 
    \item \textbf{Monitoring and Metrics} (Section~\ref{monitoring}): concerns the need for appropriate monitoring and benchmarking both for users to effectively use resources and for sites to provide resources more effectively.
    \item \textbf{End user documentation and support} (Section~\ref{documentation}): expresses the requirement for  findable, quality documentation and support for users as part of the AF infrastructure is essential.

\end{itemize} 


This White Paper does not aim to answer all the questions surrounding analysis facilities and infrastructures. We have identified remaining, key open questions for the community and they are highlighted at the end of the relevant sections.
